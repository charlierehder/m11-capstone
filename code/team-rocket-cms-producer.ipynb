{"cells":[{"cell_type":"code","source":["import os.path\n\nstorageAccount = \"gen10datafund2202\"\nstorageContainer = \"team-rocket\"\nclientSecret = \"B4g8Q~1VyZJa5WszLHwdEQNq4YIaHmT4DevRBcwI\"\nclientid = \"2ca50102-5717-4373-b796-39d06568588d\"\nmount_point = \"/mnt/team-rocket\"\n\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n       \"fs.azure.account.oauth2.client.id\": clientid,\n       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n\n# creating mount point on Azure\ntry: \n    dbutils.fs.unmount(mount_point)\nexcept:\n    pass\n\ndbutils.fs.mount(\nsource = \"abfss://\"+storageContainer+\"@\"+storageAccount+\".dfs.core.windows.net/\",\nmount_point = mount_point,\nextra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6e7866d-9a97-4307-afe6-c284ff662a4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Define Error Callbacks\ndef error_cb(err):\n    \"\"\" The error callback is used for generic client errors. These\n        errors are generally to be considered informational as the client will\n        automatically try to recover from all errors, and no extra action\n        is typically required by the application.\n        For this example however, we terminate the application if the client\n        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n        authentication errors (_AUTHENTICATION). \"\"\"\n\n    print(\"Client error: {}\".format(err))\n    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n       err.code() == KafkaError._AUTHENTICATION:\n        # Any exception raised from this callback will be re-raised from the\n        # triggering flush() or poll() call.\n        raise KafkaException(err)\n\n\ndef acked(err, msg):\n    \"\"\" \n        Error callback is used for generic issues for producer errors. \n        \n        Parameters:\n            err (err): Error flag.\n            msg (str): Error message that was part of the callback.\n    \"\"\"\n    if err is not None:\n        print(\"Failed to deliver message: %s: %s\" % (str(msg), str(err)))\n    else:\n        print(\"Message produced: %s\" % (str(msg)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10f5a3d5-3161-4da2-97a6-310642b21192"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from confluent_kafka import Consumer\nfrom time import sleep\nimport uuid\nfrom confluent_kafka import Producer, KafkaError, KafkaException\nimport json\nfrom confluent_kafka.admin import AdminClient, NewTopic\n\n#KAFKA variables, Move to the OS variables or configuration\n# This will work in local Jupiter Notebook, but in a databrick, hiding config.py is tougher. \nconfluentClusterName = \"stage3talent\"\nconfluentBootstrapServers = \"pkc-ldvmy.centralus.azure.confluent.cloud:9092\"\nschemaRegistryUrl = \"https://psrc-gq7pv.westus2.azure.confluent.cloud\"\nconfluentApiKey = \"YHMHG7E54LJA55XZ\"\nconfluentSecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\nconfluentRegistryApiKey = \"YHMHG7E54LJA55XZ\"\nconfluentRegistrySecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\n\n\n# Kafka Admin Setup\nadmin_client = AdminClient({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})\n\n#Kakfa Producer Setup.\np = Producer({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(1),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70f53f09-41cd-40ff-ab47-dc331ce96a95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import requests\nimport json\nimport time\n\n# build api query string\nbase_url = 'https://data.cms.gov/provider-data/api/1/datastore/query'\ndatasets = ['su9h-3pvj', 'avtz-f2ge', 'dgmq-aat3', 'pudb-wetr', 'ypbt-wvdk', 'c7us-v4mf'] #list of datasets being grabbed from base url\nparams = {'limit' : 100, 'offset' : 0, 'count' : 'false', 'results' : 'true', 'schema' : 'false', 'keys' : 'true', 'format' : 'json', 'rowIds' : 'false'}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87b31edd-5cb8-4c19-b797-6b97c03e66b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# delete topic (if it exists)\ntry:\n    topics = datasets\n    fs = admin_client.delete_topics(topics, request_timeout=30)\n\n    for topic, f in fs.items():\n        try:\n            f.result()  # The result itself is None\n            print(\"Topic {} deleted\".format(topic))\n        except Exception as e:\n            print(\"Failed to delete topic {}: {}\".format(topic, e))\nexcept Exception as e:\n    print(e)\nsleep(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10d8aa89-ca37-46b5-b562-057dd12a12e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Topic su9h-3pvj deleted\nTopic avtz-f2ge deleted\nTopic dgmq-aat3 deleted\nTopic pudb-wetr deleted\nTopic ypbt-wvdk deleted\nTopic c7us-v4mf deleted\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Topic su9h-3pvj deleted\nTopic avtz-f2ge deleted\nTopic dgmq-aat3 deleted\nTopic pudb-wetr deleted\nTopic ypbt-wvdk deleted\nTopic c7us-v4mf deleted\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Simple Topic Setup\n# create topic for each dataset such that each dataset can be consumed separately\ntopic_list = []\nfor dataset in datasets:\n    topic_list.append(NewTopic(dataset, 1, 3))\nfutures = admin_client.create_topics(topic_list)\n\ntry:\n    record_metadata = []\n    for k, future in futures.items():\n        # f = i.get(timeout=10)\n        print(f\"type(k): {type(k)}\")\n        print(f\"type(v): {type(future)}\")\n        print(future.result())\n\nexcept KafkaError:\n    # Decide what to do if produce request failed...\n    print(traceback.format_exc())\n    result = 'Fail'\nfinally:\n    print(\"finally\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46f7eb19-dceb-4ce8-af12-0e311444c4d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">type(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\nfinally\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">type(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\ntype(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nNone\nfinally\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import time\nimport sys\n\n# iterate through each dataset \nfor dataset in datasets:\n    url = '/'.join([base_url, dataset, '0']) # different url required for each dataset in the api \n    offset = 0 # we only grab 100 rows at a time due to kafka maximum message size constraints, hence the offset\n    while True:\n        time.sleep(2)\n        params['offset'] = offset\n        response = requests.get(url, params).json() # get json response\n        if response['results']:\n            offset += 100 # increment offset\n        else:\n            break\n        print(str(sys.getsizeof(json.dumps(response['results']))) + ':' + dataset + ':' + str(offset)) # info printout\n        p.produce(dataset, json.dumps(response['results'])) # push message to kafka as a json string\n        p.flush()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"965834c7-9290-4ccd-8254-77ab27b9cc19"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">49584:su9h-3pvj:100\n49407:su9h-3pvj:200\n49486:su9h-3pvj:300\n49501:su9h-3pvj:400\n49709:su9h-3pvj:500\n49753:su9h-3pvj:600\n49300:su9h-3pvj:700\n49258:su9h-3pvj:800\n49298:su9h-3pvj:900\n49215:su9h-3pvj:1000\n49146:su9h-3pvj:1100\n49376:su9h-3pvj:1200\n49559:su9h-3pvj:1300\n49313:su9h-3pvj:1400\n49375:su9h-3pvj:1500\n49422:su9h-3pvj:1600\n49610:su9h-3pvj:1700\n49547:su9h-3pvj:1800\n49770:su9h-3pvj:1900\n49623:su9h-3pvj:2000\n49431:su9h-3pvj:2100\n49742:su9h-3pvj:2200\n17899:su9h-3pvj:2300\n414564:avtz-f2ge:100\n414407:avtz-f2ge:200\n414481:avtz-f2ge:300\n414571:avtz-f2ge:400\n414709:avtz-f2ge:500\n414813:avtz-f2ge:600\n414290:avtz-f2ge:700\n414318:avtz-f2ge:800\n414293:avtz-f2ge:900\n414250:avtz-f2ge:1000\n414136:avtz-f2ge:1100\n414371:avtz-f2ge:1200\n414544:avtz-f2ge:1300\n414303:avtz-f2ge:1400\n414450:avtz-f2ge:1500\n414447:avtz-f2ge:1600\n414590:avtz-f2ge:1700\n414532:avtz-f2ge:1800\n414750:avtz-f2ge:1900\n414598:avtz-f2ge:2000\n414441:avtz-f2ge:2100\n414657:avtz-f2ge:2200\n149269:avtz-f2ge:2300\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">49584:su9h-3pvj:100\n49407:su9h-3pvj:200\n49486:su9h-3pvj:300\n49501:su9h-3pvj:400\n49709:su9h-3pvj:500\n49753:su9h-3pvj:600\n49300:su9h-3pvj:700\n49258:su9h-3pvj:800\n49298:su9h-3pvj:900\n49215:su9h-3pvj:1000\n49146:su9h-3pvj:1100\n49376:su9h-3pvj:1200\n49559:su9h-3pvj:1300\n49313:su9h-3pvj:1400\n49375:su9h-3pvj:1500\n49422:su9h-3pvj:1600\n49610:su9h-3pvj:1700\n49547:su9h-3pvj:1800\n49770:su9h-3pvj:1900\n49623:su9h-3pvj:2000\n49431:su9h-3pvj:2100\n49742:su9h-3pvj:2200\n17899:su9h-3pvj:2300\n414564:avtz-f2ge:100\n414407:avtz-f2ge:200\n414481:avtz-f2ge:300\n414571:avtz-f2ge:400\n414709:avtz-f2ge:500\n414813:avtz-f2ge:600\n414290:avtz-f2ge:700\n414318:avtz-f2ge:800\n414293:avtz-f2ge:900\n414250:avtz-f2ge:1000\n414136:avtz-f2ge:1100\n414371:avtz-f2ge:1200\n414544:avtz-f2ge:1300\n414303:avtz-f2ge:1400\n414450:avtz-f2ge:1500\n414447:avtz-f2ge:1600\n414590:avtz-f2ge:1700\n414532:avtz-f2ge:1800\n414750:avtz-f2ge:1900\n414598:avtz-f2ge:2000\n414441:avtz-f2ge:2100\n414657:avtz-f2ge:2200\n149269:avtz-f2ge:2300\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1f086d8-446d-4a2e-b045-3f4639e11d6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: &#39;/Users/crehder@dev-10.com/team-rocket-producer&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: &#39;/Users/crehder@dev-10.com/team-rocket-producer&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4510245-3612-46cc-b6b8-2c3d448a7c92"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"team-rocket-producer","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3135277668778891}},"nbformat":4,"nbformat_minor":0}
